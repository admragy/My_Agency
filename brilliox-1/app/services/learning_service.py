"""
Self-Learning AI Service
Learns from successful conversations to improve responses
"""
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import re
from app.core.database import DB_TYPE, pg_conn, LOCAL_DB


class LearningService:
    """AI Self-Learning Service"""
    
    BAIT_TEMPLATES = {
        "curiosity": {
            "ar": "Ù‡Ù„ Ø³Ù…Ø¹Øª Ø¹Ù† Ø§Ù„ÙØ±ØµØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ {location}ØŸ ðŸ ",
            "templates": [
                "Ù‡Ù„ Ø³Ù…Ø¹Øª Ø¹Ù† Ø§Ù„ÙØ±ØµØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ {location}ØŸ",
                "Ø¹Ù†Ø¯ÙŠ Ø­Ø§Ø¬Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ø§Ø²Ù… ØªØ¹Ø±ÙÙ‡Ø§...",
                "Ø´ÙˆÙ Ø§Ù„Ù„ÙŠ Ø­ØµÙ„ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù‚Ø§Ø±ÙŠ ðŸ‘€"
            ]
        },
        "problem": {
            "ar": "Ù‡Ù„ Ø¨ØªÙˆØ§Ø¬Ù‡ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø¥ÙŠØ¬Ø§Ø¯ {property_type} Ù…Ù†Ø§Ø³Ø¨ØŸ",
            "templates": [
                "Ù‡Ù„ Ø¨ØªÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø¥ÙŠØ¬Ø§Ø¯ Ø´Ù‚Ø© Ø¨Ø³Ø¹Ø± Ù…Ø¹Ù‚ÙˆÙ„ØŸ",
                "Ø²Ù‡Ù‚Øª Ù…Ù† Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù‚Ø§Ø± ÙƒÙˆÙŠØ³ØŸ",
                "Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù„ÙŠ Ø§Ù„ÙƒÙ„ Ø¨ÙŠØ´ØªÙƒÙŠ Ù…Ù†Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª..."
            ]
        },
        "urgency": {
            "ar": "Ø¢Ø®Ø± ÙØ±ØµØ©! Ø§Ù„Ø¹Ø±Ø¶ ÙŠÙ†ØªÙ‡ÙŠ Ø®Ù„Ø§Ù„ {hours} Ø³Ø§Ø¹Ø§Øª ÙÙ‚Ø· â°",
            "templates": [
                "Ø¢Ø®Ø± 3 ÙˆØ­Ø¯Ø§Øª Ù…ØªØ¨Ù‚ÙŠØ© Ø¨Ø§Ù„Ø³Ø¹Ø± Ø¯Ù‡!",
                "Ø§Ù„Ø¹Ø±Ø¶ ÙŠÙ†ØªÙ‡ÙŠ Ø¨ÙƒØ±Ø© - Ù„Ø§Ø²Ù… ØªØªØ­Ø±Ùƒ Ø¯Ù„ÙˆÙ‚ØªÙŠ",
                "Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù‡ØªØ²ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø¬Ø§ÙŠ ðŸ“ˆ"
            ]
        },
        "social_proof": {
            "ar": "Ø£ÙƒØ«Ø± Ù…Ù† {count} Ø¹Ù…ÙŠÙ„ Ø§Ø®ØªØ§Ø±ÙˆØ§ Ù†ÙØ³ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±",
            "templates": [
                "50+ Ø¹Ù…ÙŠÙ„ Ø­Ø¬Ø²ÙˆØ§ Ø§Ù„Ø´Ù‡Ø± Ø¯Ù‡ ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹",
                "ÙƒÙ„ Ø§Ù„Ù„ÙŠ Ø´Ø§ÙÙˆØ§ Ø§Ù„Ù…ÙƒØ§Ù† Ø¯Ù‡ Ø§ØªØ¨Ù‡Ø±ÙˆØ§",
                "Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø¨ÙŠØ±Ø¬Ø¹ÙˆØ§ ÙŠØ­Ø¬Ø²ÙˆØ§ ÙˆØ­Ø¯Ø© ØªØ§Ù†ÙŠØ© ðŸ”„"
            ]
        },
        "question": {
            "ar": "Ø¥ÙŠÙ‡ Ø§Ù„Ù„ÙŠ Ø¨ØªØ¯ÙˆØ± Ø¹Ù„ÙŠÙ‡ ÙÙŠ {property_type}ØŸ",
            "templates": [
                "Ø¥ÙŠÙ‡ Ø£Ù‡Ù… Ø­Ø§Ø¬Ø© Ø¨ØªØ¯ÙˆØ± Ø¹Ù„ÙŠÙ‡Ø§ ÙÙŠ Ø§Ù„Ø´Ù‚Ø©ØŸ",
                "Ø¹Ø§ÙŠØ² Ø§Ø³ØªØ«Ù…Ø§Ø± ÙˆÙ„Ø§ Ø³ÙƒÙ†ØŸ",
                "Ø¥ÙŠÙ‡ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ù„ÙŠ Ù†Ø§ÙˆÙŠ Ø¹Ù„ÙŠÙ‡Ø§ØŸ ðŸ’°"
            ]
        },
        "value": {
            "ar": "Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ {benefit} Ù…Ø¬Ø§Ù†Ø§Ù‹ Ù…Ø¹ Ø£ÙŠ Ø­Ø¬Ø² Ù‡Ø°Ø§ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹",
            "templates": [
                "ØªØ´Ø·ÙŠØ¨ ÙƒØ§Ù…Ù„ Ù‡Ø¯ÙŠØ© Ù…Ø¹ Ø§Ù„Ø­Ø¬Ø² ðŸŽ",
                "Ø£Ù‚Ø³Ø§Ø· Ø¨Ø¯ÙˆÙ† ÙÙˆØ§Ø¦Ø¯ Ù„Ù…Ø¯Ø© 10 Ø³Ù†ÙŠÙ†",
                "Ù…Ù‚Ø¯Ù… 10% ÙÙ‚Ø· ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ Ø¹Ù„Ù‰ 7 Ø³Ù†ÙŠÙ†"
            ]
        }
    }
    
    FUNNEL_STAGES = [
        {"id": "new", "name": "Ø¬Ø¯ÙŠØ¯", "order": 0},
        {"id": "bait_sent", "name": "ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ø¹Ù…", "order": 1},
        {"id": "replied", "name": "Ø±Ø¯", "order": 2},
        {"id": "interested", "name": "Ù…Ù‡ØªÙ…", "order": 3},
        {"id": "negotiating", "name": "ÙÙŠ Ø§Ù„ØªÙØ§ÙˆØ¶", "order": 4},
        {"id": "hot", "name": "Ø³Ø§Ø®Ù†", "order": 5},
        {"id": "closed", "name": "ØªÙ… Ø§Ù„Ø¨ÙŠØ¹", "order": 6},
        {"id": "lost", "name": "Ø®Ø³Ø§Ø±Ø©", "order": -1}
    ]
    
    @staticmethod
    def get_bait_templates() -> Dict:
        """Get all bait message templates"""
        return LearningService.BAIT_TEMPLATES
    
    @staticmethod
    def get_funnel_stages() -> List[Dict]:
        """Get all funnel stages"""
        return LearningService.FUNNEL_STAGES
    
    @staticmethod
    def generate_bait_message(template_type: str, variables: Dict = None) -> str:
        """Generate a bait message from template"""
        if template_type not in LearningService.BAIT_TEMPLATES:
            template_type = "curiosity"
        
        templates = LearningService.BAIT_TEMPLATES[template_type]["templates"]
        import random
        template = random.choice(templates)
        
        if variables:
            for key, value in variables.items():
                template = template.replace(f"{{{key}}}", str(value))
        
        return template
    
    @staticmethod
    def save_pattern(user_id: str, pattern_data: Dict) -> bool:
        """Save a learned pattern to database"""
        if DB_TYPE == "replit_pg" and pg_conn:
            try:
                cur = pg_conn.cursor()
                cur.execute("""
                    INSERT INTO ai_patterns (user_id, pattern_type, trigger_text, response_text, stage, confidence)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    ON CONFLICT DO NOTHING
                """, (
                    user_id,
                    pattern_data.get("type", "reply"),
                    pattern_data.get("trigger", ""),
                    pattern_data.get("response", ""),
                    pattern_data.get("stage", "interested"),
                    pattern_data.get("confidence", 0.5)
                ))
                pg_conn.commit()
                cur.close()
                return True
            except Exception as e:
                print(f"Save pattern error: {e}")
                return False
        
        LOCAL_DB.setdefault("ai_patterns", []).append({
            "user_id": user_id,
            **pattern_data,
            "created_at": datetime.now().isoformat()
        })
        return True
    
    @staticmethod
    def get_patterns(user_id: str, stage: str = None) -> List[Dict]:
        """Get learned patterns for user"""
        if DB_TYPE == "replit_pg" and pg_conn:
            try:
                from psycopg2.extras import RealDictCursor
                cur = pg_conn.cursor(cursor_factory=RealDictCursor)
                
                if stage:
                    cur.execute("""
                        SELECT * FROM ai_patterns 
                        WHERE user_id = %s AND stage = %s
                        ORDER BY confidence DESC, success_count DESC
                    """, (user_id, stage))
                else:
                    cur.execute("""
                        SELECT * FROM ai_patterns 
                        WHERE user_id = %s
                        ORDER BY confidence DESC, success_count DESC
                    """, (user_id,))
                
                patterns = [dict(row) for row in cur.fetchall()]
                cur.close()
                return patterns
            except Exception as e:
                print(f"Get patterns error: {e}")
                return []
        
        patterns = LOCAL_DB.get("ai_patterns", [])
        filtered = [p for p in patterns if p.get("user_id") == user_id]
        if stage:
            filtered = [p for p in filtered if p.get("stage") == stage]
        return filtered
    
    @staticmethod
    def update_pattern_success(pattern_id: int, is_success: bool) -> bool:
        """Update pattern success/fail count"""
        if DB_TYPE == "replit_pg" and pg_conn:
            try:
                cur = pg_conn.cursor()
                if is_success:
                    cur.execute("""
                        UPDATE ai_patterns 
                        SET success_count = success_count + 1,
                            confidence = (success_count + 1.0) / (success_count + fail_count + 1.0),
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = %s
                    """, (pattern_id,))
                else:
                    cur.execute("""
                        UPDATE ai_patterns 
                        SET fail_count = fail_count + 1,
                            confidence = success_count / (success_count + fail_count + 1.0),
                            updated_at = CURRENT_TIMESTAMP
                        WHERE id = %s
                    """, (pattern_id,))
                pg_conn.commit()
                cur.close()
                return True
            except Exception as e:
                print(f"Update pattern error: {e}")
                return False
        return False
    
    @staticmethod
    def import_conversation(user_id: str, platform: str, messages: List[Dict], rating: int) -> Dict:
        """Import and analyze a conversation"""
        patterns_found = []
        
        for i, msg in enumerate(messages):
            if msg.get("is_mine") and i > 0:
                prev_msg = messages[i-1]
                if not prev_msg.get("is_mine"):
                    pattern = {
                        "type": "reply",
                        "trigger": prev_msg.get("text", "")[:200],
                        "response": msg.get("text", "")[:500],
                        "stage": LearningService._detect_stage(prev_msg.get("text", "")),
                        "confidence": min(0.3 + (rating * 0.1), 0.9)
                    }
                    patterns_found.append(pattern)
                    LearningService.save_pattern(user_id, pattern)
        
        if DB_TYPE == "replit_pg" and pg_conn:
            try:
                cur = pg_conn.cursor()
                cur.execute("""
                    INSERT INTO conversation_imports (user_id, platform, conversation_data, rating, is_successful, patterns_extracted)
                    VALUES (%s, %s, %s, %s, %s, %s)
                """, (
                    user_id,
                    platform,
                    json.dumps(messages, ensure_ascii=False),
                    rating,
                    rating >= 4,
                    len(patterns_found)
                ))
                pg_conn.commit()
                cur.close()
            except Exception as e:
                print(f"Import conversation error: {e}")
        
        return {
            "patterns_found": len(patterns_found),
            "is_successful": rating >= 4
        }
    
    @staticmethod
    def _detect_stage(text: str) -> str:
        """Detect conversation stage from text"""
        text_lower = text.lower() if text else ""
        
        if any(w in text_lower for w in ["Ø³Ø¹Ø±", "ÙƒØ§Ù…", "Ø«Ù…Ù†", "ØªÙƒÙ„ÙØ©", "Ù…Ø¨Ù„Øº"]):
            return "interested"
        if any(w in text_lower for w in ["Ù…ÙˆØ§ÙÙ‚", "ØªÙ…Ø§Ù…", "Ø£ÙˆÙƒÙŠ", "Ù…Ø§Ø´ÙŠ", "Ø­Ø§Ø¶Ø±"]):
            return "negotiating"
        if any(w in text_lower for w in ["Ù…Ø´ Ù…Ù‡ØªÙ…", "Ù„Ø§ Ø´ÙƒØ±Ø§", "Ù…Ø´ Ø¹Ø§ÙŠØ²"]):
            return "lost"
        if any(w in text_lower for w in ["Ù‡Ø­Ø¬Ø²", "Ø®Ù„Ø§Øµ", "Ø§ØªÙÙ‚Ù†Ø§", "done", "ØªÙ…"]):
            return "closed"
        if any(w in text_lower for w in ["Ø·ÙŠØ¨", "Ø®Ù„ÙŠÙ†Ø§ Ù†Ø´ÙˆÙ", "Ù…Ù…ÙƒÙ†", "Ø¹Ø§ÙŠØ² Ø§Ø¹Ø±Ù"]):
            return "replied"
        
        return "bait_sent"
    
    @staticmethod
    def generate_smart_reply(user_id: str, customer_message: str, stage: str) -> str:
        """Generate a smart reply based on learned patterns"""
        patterns = LearningService.get_patterns(user_id, stage)
        
        if patterns:
            import random
            best_patterns = [p for p in patterns if p.get("confidence", 0) > 0.5]
            if best_patterns:
                pattern = random.choice(best_patterns[:5])
                return pattern.get("response_text", "")
        
        default_replies = {
            "new": "Ø£Ù‡Ù„Ø§Ù‹ Ø¨ÙŠÙƒ! ðŸ‘‹ Ø¥Ø²ÙŠÙƒØŸ Ø¹Ù†Ø¯ÙŠ Ø¹Ø±Ø¶ Ù…Ù…ÙŠØ² Ø¬Ø¯Ø§Ù‹ Ù…Ù…ÙƒÙ† ÙŠØ¹Ø¬Ø¨Ùƒ...",
            "bait_sent": "ØªÙ…Ø§Ù…ØŒ Ø£Ù†Ø§ ØªØ­Øª Ø£Ù…Ø±Ùƒ. Ø¥ÙŠÙ‡ Ø§Ù„Ù„ÙŠ ØªØ­Ø¨ ØªØ¹Ø±ÙÙ‡ Ø£ÙƒØªØ±ØŸ",
            "replied": "Ø¬Ù…ÙŠÙ„ Ø¬Ø¯Ø§Ù‹! ðŸ˜Š Ø®Ù„ÙŠÙ†ÙŠ Ø£ÙˆØ¶Ø­Ù„Ùƒ Ø§Ù„ØªÙØ§ØµÙŠÙ„...",
            "interested": "Ù…Ù…ØªØ§Ø²! ðŸ”¥ Ø¯Ù‡ ÙØ¹Ù„Ø§Ù‹ Ø£Ø­Ø³Ù† ÙˆÙ‚Øª Ù„Ù„Ø­Ø¬Ø². Ø¹Ø§ÙŠØ² Ø£Ø¨Ø¹ØªÙ„Ùƒ Ø§Ù„ÙƒØªØ§Ù„ÙˆØ¬ØŸ",
            "negotiating": "Ø·Ø¨Ø¹Ø§Ù‹ Ù†Ù‚Ø¯Ø± Ù†ØªÙØ§Ù‡Ù…. Ø¥ÙŠÙ‡ Ø§Ù„Ù„ÙŠ ÙŠÙ†Ø§Ø³Ø¨Ùƒ Ø¨Ø§Ù„Ø¸Ø¨Ø·ØŸ",
            "hot": "Ø®Ù„Ø§Øµ ÙƒØ¯Ù‡! ðŸŽ‰ Ø£Ù…ØªÙ‰ Ù†Ù‚Ø¯Ø± Ù†Ø¹Ù…Ù„ Ø§Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©ØŸ",
            "closed": "Ù…Ø¨Ø±ÙˆÙƒ Ø¹Ù„ÙŠÙƒ! ðŸŽŠ Ù‡ØªØ³ØªÙ…ØªØ¹ Ø¬Ø¯Ø§Ù‹.",
            "lost": "ØªÙ…Ø§Ù…ØŒ Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ø£ÙŠ Ø­Ø§Ø¬Ø© ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯."
        }
        
        return default_replies.get(stage, default_replies["replied"])
    
    @staticmethod
    def get_learning_stats(user_id: str) -> Dict:
        """Get learning statistics for user"""
        patterns = LearningService.get_patterns(user_id)
        
        total_patterns = len(patterns)
        avg_confidence = sum(p.get("confidence", 0) for p in patterns) / max(total_patterns, 1)
        
        stage_counts = {}
        for p in patterns:
            stage = p.get("stage", "unknown")
            stage_counts[stage] = stage_counts.get(stage, 0) + 1
        
        conversations_imported = 0
        if DB_TYPE == "replit_pg" and pg_conn:
            try:
                cur = pg_conn.cursor()
                cur.execute("SELECT COUNT(*) FROM conversation_imports WHERE user_id = %s", (user_id,))
                result = cur.fetchone()
                conversations_imported = result[0] if result else 0
                cur.close()
            except:
                pass
        
        return {
            "total_patterns": total_patterns,
            "avg_confidence": round(avg_confidence * 100, 1),
            "patterns_by_stage": stage_counts,
            "conversations_imported": conversations_imported,
            "improvement_level": "Ù…Ø¨ØªØ¯Ø¦" if total_patterns < 10 else "Ù…ØªÙˆØ³Ø·" if total_patterns < 50 else "Ù…ØªÙ‚Ø¯Ù…"
        }
